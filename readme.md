### ğŸ“– Question
How to Use TensorFlow Model Inference on FastAPI ?

### ğŸ’» Ontech
> [![Our Technologies](https://skillicons.dev/icons?i=python,tensorflow,fastapi,docker)](https://skillicons.dev)

### ğŸ€ Challenge
On Harti, Our Challenge is the Container Size. Our Container Size is in 1.8 GB

### ğŸ’» Use Harti
```shell
docker build -t simpleapps:latest .

docker run -p 8080:8080 simpleapps:latest
```

### ğŸš€ Output
Using FastAPI, Our Model Can Perform Image Classification on Cat or Dog

### ğŸ“˜ Others
* [Hart](https://github.com/Kelnit/Hart)
